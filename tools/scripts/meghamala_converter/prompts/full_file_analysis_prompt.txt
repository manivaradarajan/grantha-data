You are an expert system specializing in LLM performance optimization and Sanskrit text analysis. Your task is to perform a complete analysis of the provided markdown document and produce a single, unified JSON response containing four sections: `metadata`, `structural_analysis`, `chunking_strategy`, and `parsing_instructions`.

Your entire response must be a single, valid JSON object. Do not include any explanatory text or markdown formatting (like ```json) before or after the JSON object.

---

### **1. Metadata Section (`metadata`):**
Extract the metadata as described below.
*   `canonical_title`: Full Sanskrit name.
*   `grantha_id`: Standardized ID.
*   `commentary_id`: Commentary ID or `null`.
*   `commentator`: Commentator name or `null`.

---

### **2. Structural Analysis Section (`structural_analysis`):**
Analyze and define the hierarchical structure of the document.
*   **Goal:** Identify all levels of division from the largest to the smallest (e.g., Prapathaka -> Khanda -> Mantra).
*   **Output:** Represent this hierarchy as a nested JSON object under the `structure_levels` key. For each level, provide a `key` (PascalCase), and `scriptNames` for both Devanagari and roman scripts.

---

### **3. Chunking Strategy Section (`chunking_strategy`):**
Devise an optimal, deterministic chunking strategy following a strict validation protocol.

**Protocol:**
1.  **Goal:** Maximize chunk size to minimize API calls.
2.  **Hard Rule:** Never split a primary section (e.g., `खण्डः`) internally.
3.  **Calculation and Validation (CRITICAL):**
    *   For each chunk you propose in the `execution_plan`, you **MUST** calculate its character length and report it in the `estimated_character_count` field.
    *   This `estimated_character_count` **MUST NOT** exceed the `safety_character_limit` of **125,000**.
    *   **Self-Correction:** Before finalizing your response, you must verify this condition for all chunks. If any chunk violates the limit, you must split that chunk into two or more smaller, compliant chunks (breaking only at a valid `खण्डः` boundary) and regenerate the plan until all chunks pass validation.
*   **Output:** Provide a machine-readable `execution_plan` that adheres to this protocol.

---

### **4. Parsing Instructions Section (`parsing_instructions`):**
Provide instructions for parsing the primary structural units (e.g., `खण्डः`) *within* each chunk.
*   `recommended_unit`: Name of the logical unit to parse.
*   `start_pattern`: Object with description, examples, and regex.
*   `end_pattern`: Object with description, examples, and regex.
*   `pre_content_handling`: Instructions for initial text like `शान्तिपाठः`.

---

### **Complete JSON Output Example:**
This is a hypothetical example for a different text to show the exact final structure you must produce. Your output should follow this structure precisely.

```json
{
  "metadata": {
    "canonical_title": "छान्दोग्योपनिषत्",
    "grantha_id": "chhandogya-upanishad",
    "commentary_id": "rangaramanuja-muni-prakashika",
    "commentator": "श्रीरङ्गरामानुजमुनि",
    "structure_type": "khanda"
  },
  "structural_analysis": {
    "structure_levels": {
      "key": "Prapathaka",
      "scriptNames": {
        "devanagari": "प्रपाठकः",
        "roman": "prapāṭhaka"
      },
      "children": {
        "key": "Khanda",
        "scriptNames": {
          "devanagari": "खण्डः",
          "roman": "khaṇḍa"
        },
        "children": {
          "key": "Mantra",
          "scriptNames": {
            "devanagari": "मन्त्रः",
            "roman": "mantra"
          }
        }
      }
    }
  },
  "chunking_strategy": {
    "proposed_strategy": {
      "name": "Validated Group by Character Count",
      "description": "This strategy combines consecutive Khandas, strictly ensuring no chunk exceeds the safety character limit. The plan is regenerated internally if any proposed chunk is too large.",
      "safety_character_limit": 125000
    },
    "execution_plan": [
      {
        "chunk_id": 1,
        "description": "Prefatory material and Khandas 1 through 7.",
        "start_marker": "शान्तिपाठः",
        "end_marker": "।। इति सप्तमखण्डभाष्यम् ।।",
        "estimated_character_count": 48500
      },
      {
        "chunk_id": 2,
        "description": "Khandas 8 through 13.",
        "start_marker": "**अष्टमः खण्डः**",
        "end_marker": "।। इति प्रथमप्रपाठकप्रकाशिका ।。",
        "estimated_character_count": 45200
      }
    ]
  },
  "parsing_instructions": {
    "recommended_unit": "Khanda",
    "justification": "The Prapathaka is primarily divided into Khandas, which are the main semantic and structural sections.",
    "start_pattern": {
      "description": "A new Khanda begins with a bolded heading indicating its number.",
      "examples": [
        "**प्रथमः खण्डः**",
        "**द्वितीयः खण्डः**"
      ],
      "regex": "\\*\\*([\\u0900-\\u097F]+) खण्डः\\*\\*"
    },
    "end_pattern": {
      "description": "The end of a Khanda is marked by a concluding line, typically mentioning the end of the section's commentary.",
      "examples": [
        "।। इति प्रथमखण्डभाष्यम् ।।",
        "।। इति द्वितीयखण्डभाष्यम् ।।"
      ],
      "regex": "।। इति .*?खण्डभाष्यम् ।।"
    },
    "pre_content_handling": "Handle the initial 'शान्तिपाठः' as a 'Prefatory' section before the first Khanda."
  }
}
```

---

**Now, analyze the following document and generate the single, unified JSON response.**

--- START OF DOCUMENT ---
{input_text}
--- END OF DOCUMENT ---
